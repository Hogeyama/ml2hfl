\input{macro}

\section{Predicate Discovery}

In this section, we propose a new predicate discovery method for 
higher-order programs.  The method is based on our previous one used by 
MoCHi~\cite{KobayashiPLDI2011}.  We briefly overview it below.

In MoCHi, predicates for abstracting each term of a given program are 
specified as a kind of dependent types called abstraction types.  MoCHi 
infers abstraction types automatically in a counterexample-guided manner: 
 In a CEGAR iteration of MoCHi, if the predicate abstraction at that 
point is not precise enough to show the safety of the original program, 
an error path of the abstracted program is returned as a result of 
higher-order model checking (see Fig.~\ref{fig:cegar}).  If the abstract 
error path is infeasible (i.e., not a genuine path of the original 
program), MoCHi generates a straightline higher-order program (SHP) 
which is safe if and only if the abstract error path is infeasible .  
MoCHi then uses an existing method~\cite{Unno2009} to infer refinement 
types that witness the safety of the SHP.  Finally, MoCHi extracts 
abstraction types from the refinement types, which contain precise 
enough predicates to refute the infeasible error path.

Our new predicate discovery method is based on the above framework but 
the component for refinement type inference is extended so that it can 
consider information from multiple calling contexts in multiple 
infeasible error paths.  This enables MoCHi to infer a general 
refinement type that type-checks the multiple calling contexts, while 
preserving the path- and context- sensitivity.  Our new refinement type 
inference method consists of two steps: constraint generation and 
solving, which are respectively explained in Sections~\ref{sec:cg} and 
\ref{sec:cs}.

\subsection{Constraint Generation}
\label{sec:cg}

In this section, we extend the constraint generation algorithm used in 
previous work~\cite{Unno2009,Terauchi2010,KobayashiPLDI2011}.  Before we 
discuss the extension, we briefly overview the previous algorithm.  Let 
us assume that we are given a SHP \(D\) which is typable under a 
refinement type system (see e.g., \cite{Unno2009} for the definition) if 
and only if the abstract error trace is infeasible.  For example, for 
the program and the error trace in Section~\ref{sec:intro}, we obtain 
the following SHP \(D_0\):\todo{}
%

From the SHP \(D\), we generate Horn-clause-like constraints which are 
satisfiable if and only if \(D\) is typable.  To this end, for each 
function in \(D\), we prepare a refinement type template with predicate 
variables, which act as placeholders of refinement predicates to be 
inferred.  We then generate a typing derivation for \(D\) under the type 
environment that associates each function with its type template.  
Horn-clause-like constraints on the predicate variables are then 
extracted from the derivation.  Since the SHP \(D\) is recursion-free 
and linear (i.e., each function is called exactly once), generated 
constraints are non-recursive.  This is desirable since constraint 
solving of non-recursive Horn clauses over linear arithmetic is 
decidable.  For the example SHP \(D_0\), we obtain the following Horn 
clauses:\todo{}

We extend the previous algorithm overviewed above as follows.
\begin{itemize}
\item For each CEGAR iteration, we infer refinement types from multiple 
infeasible error paths instead of a single path:  We keep the set 
\(\set{\pi_1,\cdots,\pi_n}\) of the infeasible error paths found so far, 
generate the set \(C_i\) of Horn clauses for each path \(\pi_i\), and 
pass \(C_1 \cup \dots \cup C_n\) to the constraint solving algorithm 
described in Section~\ref{sec:cs} as an input.  For example, \todo{}
\item We also pass an equivalence relation \(E\) on the predicate 
variables in \(C_1 \cup \dots \cup C_n\) such that \(P\ E\ Q\) if and 
only if the predicate variables \(P\) and \(Q\) represent (possibly 
different) refinement predicates for the same argument of the same 
function in the original program.  The constraint solving algorithm in 
Section~\ref{sec:cs} exploits \(E\) to find general solutions for the 
constraints.  For example, \todo{}
\end{itemize}

%%%We then use the constraint generation algorithm for terms defined in 
%%%Figure~\ref{fig:cgen} to obtain constraints.  In the figure, 
%%%$\CG{\Gamma}{e}$ returns a pair of a refinement type $\tau$ and a 
%%%constraint $\theta$ such that $\Gamma \vdash e : \tau$ is derivable if 
%%%and only if $\theta$ is valid. Similarly, $\CS{\Gamma}{\tau_1}{\tau_2}$ 
%%%returns a constraint $\theta$ such that $\Gamma \vdash \tau_1 \leq 
%%%\tau_2$ is derivable if and only if $\theta$ is valid.
%%%%
%%%The algorithm is almost a straightforward modification of the typing and 
%%%subtyping rules in Section~\ref{sec:reftypesystem} except that the 
%%%application of the subsumption rule is restricted to the acutal argument 
%%%of function applications.


%%%\begin{figure*}[tbh]
%%%\begin{eqnarray*}
%%%\CG{\Gamma}{x}
%%%&=&(\reftype{u}{u = x},\top) \quad (\mbox{if}~\sty{x}=\inttype) \\
%%%\CG{\Gamma}{\kappa}
%%%&=&(\Gamma(\kappa),\top) \quad (\mbox{if}~\sty{\kappa} \in \rightarrow) \\
%%%\CG{\Gamma}{c}
%%%&=&(\cty{c},\top) \\
%%%\CG{\Gamma}{\ttlet{x}{e_1}{e_2}}
%%%&=&\mbox{let~}(\sigma,\theta_1)=\CG{\Gamma}{e_1} \\
%%%& &\mbox{let~}(\cpstype,\theta_2)=\CG{\Gamma,x\smallcolon\sigma}{e_2} \\
%%%& &(\cpstype,\theta_1 \land \theta_2) \\
%%%\CG{\Gamma}{\ttapp{e}{x}}
%%%&=&\mbox{let~}(\funtype{y}{\sigma}{\tau},\theta_1)=\CG{\Gamma}{e} \\
%%%& &\mbox{let~}(\sigma',\theta_2)=\CG{\Gamma}{x} \\
%%%& &(\tau[x/y],\theta_1 \land \theta_2 \land \CS{\Gamma}{\sigma'}{\sigma}) \\
%%%\CG{\Gamma}{\ttifndet{e_1}{e_2}}
%%%&=&\mbox{let~}(\cpstype,\theta_1)=\CG{\Gamma}{e_1} \\
%%%& &\mbox{let~}(\cpstype,\theta_2)=\CG{\Gamma}{e_2} \\
%%%& &(\cpstype,\theta_1 \land \theta_2) \\
%%%\CS{\Gamma}{\cpstype}{\cpstype}
%%%&=&\top \\
%%%\CS{\Gamma}{\funtype{x}{\sigma_1}{\tau_1}}{\funtype{x}{\sigma_2}{\tau_2}}
%%%&=&\CS{\Gamma}{\sigma_2}{\sigma_1} \land \CS{\Gamma,x:\sigma_2}{\tau_1}{\tau_2} \\
%%%\CS{\Gamma}{\reftype{u}{\theta_1}}{\reftype{u}{\theta_2}}
%%%&=&\forall u.(\sembrack{\Gamma} \wedge \theta_1) \Rightarrow \theta_2  \quad (\mbox{if}~u \notin \free{\sembrack{\Gamma}})
%%%\end{eqnarray*}
%%%\caption{Constraint generation algorithm.}
%%%\label{fig:cgen}
%%%\end{figure*}



\subsection{Constraint Solving}
\label{sec:cs}

%%%In fact, the previous algorithm can solve them by using 

\todo{explain a high-level idea of the algorithm.} Given a set \(C\) of 
Horn clauses and an equivalence relation \(E\) on the predicate 
variables in \(C\), our new constraint solving algorithm proceeds as 
follows.  First, we compute the strongest lower \(\lambda \seq{x}\lambda 
\nu.\phi_P\) and the weakest upper \(\lambda \seq{x}\lambda \nu.\phi_P'\) 
bounds for each predicate variable \(P\) in \(C\).  Here, \(\FV{\phi_P} 
\subseteq \set{\seq{x},\nu}\) and \(\FV{\phi_P'} \subseteq 
\set{\seq{x},\nu}\).  Intuitively, \(P\) represents an invariant of some 
subexpression \(e\) of a SHP such that \(\FV{e} \subseteq \set{\seq{x}}\), 
and \(\nu\) represents the value of \(e\).  The lower \(\phi_P\) and the 
upper \(\phi_{P}'\) bounds for \(P\) respectively represent the 
strongest condition on the value \(\nu\) and the weakest condition on 
the value \(\nu\) which is required by the context of \(e\).  For 
example, \todo{}  In general, the computation of the upper bound for 
some predicate variable may possibly fail because the constraint 
generation algorithm in Section~\ref{sec:cg} may generate a Horn clause 
of the form \(P(x) \land P(y) \Rightarrow \phi\).  Note here that \(P\) 
occurs twice in the left hand side of the constraint.  In such a case, 
the weakest upper bound for \(P\) may not exist.

Let \(S\) be the set of predicate variables in \(C\) whose upper bounds 
were successfully computed.  We then pick an equivalence class \(S_0 \in 
S / E\) (e.g., the largest one), and classify the predicate variables in 
\(S_0\) into related groups.  \todo{explain ``related''}  Formally, we 
find \(S_1\dots,S_n\) such that:
\begin{itemize}
\item \(S_0 = S_1 \cup \dots \cup S_n\),
\item for any \(i \in \set{1,\dots,n}\), if \(S_i = 
\set{Q_1,\dots,Q_{\ell}}\), then \(\phi_{Q_1} \lor \dots \lor 
\phi_{Q_{\ell}}\) implies \(\phi_{Q_1}' \land \dots \land 
\phi_{Q_{\ell}}'\), and
\item for any \(i,j \in \set{1,\dots,n}\), if \(i \neq j\) and 
\(S_i \cup S_j = \set{Q_1,\dots,Q_{\ell}}\), then \(\phi_{Q_1} \lor 
\dots \lor \phi_{Q_{\ell}}\) does not imply \(\phi_{Q_1}' \land \dots 
\land \phi_{Q_{\ell}}'\).
\end{itemize}
For example, \todo{}

We then pick some \(S_i = \set{Q_1,\dots,Q_{\ell}} \in 
\set{S_1,\dots,S_n}\) (e.g., the largest one) and find a formula \(\phi\) 
such that:
\begin{itemize}
\item \(\phi_{Q_1} \lor \dots \lor \phi_{Q_{\ell}}\) implies \(\phi\),
\item \(\phi\) implies \(\phi_{Q_1}' \land \dots \land \phi_{Q_{\ell}}'\), and
\item \(\FV{\phi} \subseteq \set{\seq{x},\nu}\).
\end{itemize}
%Terauchi2010
We can compute such a formula \(\phi\) as an interpolant 
\(\mathcal{I}(\phi_{Q_1} \lor \dots \lor \phi_{Q_{\ell}},\neg 
(\phi_{Q_1}' \land \dots \land \phi_{Q_{\ell}}'))\) by using a technique 
called interpolation~\cite{Henzinger2004,McMillan2005} from automated 
theorem proving.  Here, an interpolant \(\mathcal{I}(\phi_1,\phi_2)\) of 
\(\phi_1\) and \(\phi_2\) (such that \(\phi_1\) and \(\phi_2\) are 
inconsistent) is a formula \(\phi\) that satisfies the following 
conditions:\footnote{Note here that interpolants of \(\phi_1\) and 
\(\phi_2\) are not unique.  Actually, existing theorem 
provers~\cite{Henzinger2004,McMillan2005,Beyer2008} return one of them.  
We denote such an interpolant as \(\mathcal{I}(\phi_1,\phi_2)\).}
\begin{itemize}
\item \(\phi_1\) implies \(\phi\),
\item \(\phi\) and \(\phi_2\) are inconsistent, and
\item \(\FV{\phi} \subseteq \FV{\phi_1} \cap \FV{\phi_2}\).
\end{itemize}
The above conditions of interpolants, however, are not always sufficient 
for our purpose to find general predicates;  Actually, we want to obtain 
as simple interpolant as possible with respect to the number of 
disjunctions.
% and conjunctions.
To this end, we propose a new heuristic operator \(\mathcal{J}\) that 
combines the interpolation \(\mathcal{I}\) and the convex hull operators. 
 Let us write \(\mathcal{H}(\phi)\) to denote the convex hull of \(\phi\). 
 For formulas \(\phi_1\) and \(\phi_2\) (such that \(\phi_1\) and 
\(\phi_2\) are inconsistent), the new operator 
\(\mathcal{J}(\phi_1,\phi_2)\) is defined as follows:
\begin{eqnarray*}
\mathcal{J}(\phi_1,\phi_2) =
\left\{
\begin{array}{ll}
\mathcal{I}(\mathcal{H}(\phi_1),\mathcal{H}(\phi_2)) & (\mbox{if~}\mathcal{H}(\phi_1) \INCON \mathcal{H}(\phi_2)) \\
\mathcal{I}(\mathcal{H}(\phi_1),\phi_2) & (\mbox{if~}\neg (\mathcal{H}(\phi_1) \INCON \mathcal{H}(\phi_2)) \land \\
&\ \quad \mathcal{H}(\phi_1) \INCON \phi_2) \\
\mathcal{I}(\phi_1,\phi_2) & (\mbox{otherwise})
\end{array}
\right.
\end{eqnarray*}
Here, we write \(\phi_1 \INCON \phi_2\) to denote that \(\phi_1\) and 
\(\phi_2\) are inconsistent.  Note that the use of the convex hull 
operator enables us to eliminate disjunctions in \(\phi_1\) and 
\(\phi_2\), which are passed to an interpolating theorem prover.
%the interpolation operator \(\mathcal{I}\).
In the experiments reported in Section~\ref{sec:experiments}, this often 
reduced the number of disjunctions in the output of the interpolating 
prover, and hence makes the output more likely to constitute invariants.
%
Thus, instead of using the interpolation operator \(\mathcal{I}\) alone, 
we use the new operator \(\mathcal{J}\) to compute 
\(\mathcal{J}(\phi_{Q_1} \lor \dots \lor \phi_{Q_{\ell}},\neg 
(\phi_{Q_1}' \land \dots \land \phi_{Q_{\ell}}'))\) as a candidate 
solution for \(Q_1,\dots,Q_{\ell}\).  For example, \todo{}

Note, however, that \(\mathcal{J}(\phi_{Q_1} \lor \dots \lor 
\phi_{Q_{\ell}},\neg (\phi_{Q_1}' \land \dots \land \phi_{Q_{\ell}}'))\) 
is not always a genuine solution for all the predicates 
\(Q_1,\dots,Q_{\ell} \in S_i\) because \(Q_i\) may depend on \(Q_j\) for 
some \(i \neq j\).  For example, let us consider the following 
constraints: \todo{}
%\begin{eqnarray*}
%x=0 &\Rightarrow& Q_1(x) \\
%Q_1(x) \land y=x &\Rightarrow& Q_2(y) \\
%Q_2(y) &\Rightarrow& y=0
%\end{eqnarray*}
Therefore, we find a maximal subset \(M\) of \(S_i\) such that 
\(\mathcal{J}(\phi_{Q_1} \lor \dots \lor \phi_{Q_{\ell}},\neg 
(\phi_{Q_1}' \land \dots \land \phi_{Q_{\ell}}'))\) is in fact a 
solution for every predicate variable in \(M\).  We then substitutes the 
solution for \(Q_1,\dots,Q_{\ell}\) in \(C\), and repeat the entire 
constraint solving procedure until every predicate variable in \(C\) is 
substituted.  \todo{discuss termination?}  \todo{add examples}


%%%infer a refinement type of each 
%%%subexpression \(e\) of an ordinary ML type \(\tau\):
%%%  The method then computes an 
%%%interpolant \(\phi\) of \(\phi_{post}\) and \(\phi_{pre}\), and returns 
%%%\(\set{\nu:\tau \mid \phi}\) as a refinement type of \(e\).
%
%%%%Thus, the method considers both forward and backward information of \(e\) 
%%%%respectively obtained from \(e\) and the context of \(e\).
