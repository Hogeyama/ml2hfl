\input{macro}

\section{Predicate Discovery}
\label{sec:refine}

In this section, we propose an extension of our previous predicate 
discovery method for higher-order programs used in 
MoCHi~\cite{KobayashiPLDI2011}.  First, we briefly overview the previous 
method in Section~\ref{sec:prev} and then discuss its limitation in 
Section~\ref{sec:limit}. Section~\ref{sec:ext} explains the extension of 
the method, which remedies the limitation.

\subsection{Previous Method}
\label{sec:prev}

In MoCHi, predicates for abstracting each term of a given program are 
specified as a kind of dependent types called abstraction types.  MoCHi 
infers abstraction types automatically in a counterexample-guided manner 
(see Figure~\ref{fig:cegar}): In a CEGAR iteration of MoCHi, if the 
predicate abstraction at that point is not precise enough to show the 
safety of the original program, an error path of the abstracted program 
is returned as a result of higher-order model checking.  If the abstract 
error path is infeasible (i.e., not a genuine path of the original 
program), MoCHi generates a straightline higher-order program (SHP) 
which is safe if and only if the abstract error path is infeasible . 
MoCHi then uses an existing method~\cite{Unno2009} to infer refinement 
types that witness the safety of the SHP.  Finally, MoCHi extracts 
abstraction types from the refinement types, which contain precise 
enough predicates to refute the infeasible error path.

The key ingredient of the above predicate discovery procedure is the 
refinement type inference 
method~\cite{Unno2009,Terauchi2010,KobayashiPLDI2011}, which consists of 
two steps: constraint generation and solving.  We review the two steps 
respectively in Sections~\ref{sec:cg} and \ref{sec:cs}.

\subsubsection{Constraint Generation}
\label{sec:cg}

\begin{figure}[t]
\begin{alltt}
let rec copy x = if x=0 then 0 else 1 + copy (x-1)
let main n = assert (copy n = n)
\end{alltt}
\caption{A Simplified Version of the Program in Figure~\ref{fig:copy}}
\label{fig:copy2}
\end{figure}

Let us assume that we are given a SHP \(D\) which is typable under a 
refinement type system (see e.g., \cite{Unno2009} for the definition) if 
and only if the abstract error path is infeasible.  For example, let us 
consider the program in Figure~\ref{fig:copy2}, which is a simplified 
version of the one in Figure~\ref{fig:copy}.  In the course of its 
verification, we may obtain the following SHP \(D_{\texttt{copy}}\):
\begin{alltt}
let copy1 x = assume (x<>0); 1 + copy2 (x-1)
let copy2 x = assume (x=0); 0
let main n = assume (copy1 n <> n); fail
\end{alltt}
The SHP corresponds to an infeasible error path where the else- and the 
then-branches of \(\texttt{copy}\) are respectively taken in the first 
and the second function call of \(\texttt{copy}\), and the assertion in 
the \(\texttt{main}\) function fails.  Note here that 
\(D_{\texttt{copy}}\) is safe (i.e., \texttt{fail} is not reachable), 
and hence is typable under the refinement type system~\cite{Unno2009}.

From a SHP \(D\), we generate Horn-clause-like constraints which are 
satisfiable if and only if \(D\) is typable.  To this end, for each 
function in \(D\), we prepare a refinement type template with predicate 
variables, which act as placeholders of refinement predicates to be 
inferred.  We then generate a typing derivation for \(D\) under the type 
environment that associates each function with its type template. 
Horn-clause-like constraints on the predicate variables are then 
extracted from the derivation.  Since the SHP \(D\) is recursion-free 
and linear (i.e., each function is called exactly once), generated 
constraints are non-recursive.  This is desirable since constraint 
solving of non-recursive Horn clauses over linear arithmetic is 
decidable.  For example, for the SHP \(D_{\texttt{copy}}\), we prepare 
the following type templates:\footnote{For the sake of simplicity, we 
here omit the type template of \texttt{main} as well as the refinement 
predicates for the argument of \texttt{copy1} and \texttt{copy2}.}
\begin{eqnarray*}
\texttt{copy1}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid P_1(x,\nu)}}) \\
\texttt{copy2}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid P_2(x,\nu)}})
\end{eqnarray*}
By using them, we obtain the following set \(C_{\texttt{copy}}\) of
constraints:
\begin{eqnarray*}
P_2(x-1,y) \land x\neq0 \land z=1+y &\imply& P_1(x,z) \\
x=0 \land y=0 &\imply& P_2(x,y) \\
P_1(n,x) &\imply& x=n
\end{eqnarray*}

%%%We then use the constraint generation algorithm for terms defined in
%%%Figure~\ref{fig:cgen} to obtain constraints.  In the figure,
%%%$\CG{\Gamma}{e}$ returns a pair of a refinement type $\tau$ and a
%%%constraint $\theta$ such that $\Gamma \vdash e : \tau$ is derivable if
%%%and only if $\theta$ is valid. Similarly, $\CS{\Gamma}{\tau_1}{\tau_2}$
%%%returns a constraint $\theta$ such that $\Gamma \vdash \tau_1 \leq
%%%\tau_2$ is derivable if and only if $\theta$ is valid.
%%%%
%%%The algorithm is almost a straightforward modification of the typing and
%%%subtyping rules in Section~\ref{sec:reftypesystem} except that the
%%%application of the subsumption rule is restricted to the acutal argument
%%%of function applications.

%%%\begin{figure*}[tbh]
%%%\begin{eqnarray*}
%%%\CG{\Gamma}{x}
%%%&=&(\reftype{u}{u = x},\top) \quad (\mbox{if}~\sty{x}=\inttype) \\
%%%\CG{\Gamma}{\kappa}
%%%&=&(\Gamma(\kappa),\top) \quad (\mbox{if}~\sty{\kappa} \in \rightarrow) \\
%%%\CG{\Gamma}{c}
%%%&=&(\cty{c},\top) \\
%%%\CG{\Gamma}{\ttlet{x}{e_1}{e_2}}
%%%&=&\mbox{let~}(\sigma,\theta_1)=\CG{\Gamma}{e_1} \\
%%%& &\mbox{let~}(\cpstype,\theta_2)=\CG{\Gamma,x\smallcolon\sigma}{e_2} \\
%%%& &(\cpstype,\theta_1 \land \theta_2) \\
%%%\CG{\Gamma}{\ttapp{e}{x}}
%%%&=&\mbox{let~}(\funtype{y}{\sigma}{\tau},\theta_1)=\CG{\Gamma}{e} \\
%%%& &\mbox{let~}(\sigma',\theta_2)=\CG{\Gamma}{x} \\
%%%& &(\tau[x/y],\theta_1 \land \theta_2 \land \CS{\Gamma}{\sigma'}{\sigma}) \\
%%%\CG{\Gamma}{\ttifndet{e_1}{e_2}}
%%%&=&\mbox{let~}(\cpstype,\theta_1)=\CG{\Gamma}{e_1} \\
%%%& &\mbox{let~}(\cpstype,\theta_2)=\CG{\Gamma}{e_2} \\
%%%& &(\cpstype,\theta_1 \land \theta_2) \\
%%%\CS{\Gamma}{\cpstype}{\cpstype}
%%%&=&\top \\
%%%\CS{\Gamma}{\funtype{x}{\sigma_1}{\tau_1}}{\funtype{x}{\sigma_2}{\tau_2}}
%%%&=&\CS{\Gamma}{\sigma_2}{\sigma_1} \land \CS{\Gamma,x:\sigma_2}{\tau_1}{\tau_2} \\
%%%\CS{\Gamma}{\reftype{u}{\theta_1}}{\reftype{u}{\theta_2}}
%%%&=&\forall u.(\sembrack{\Gamma} \wedge \theta_1) \imply \theta_2  \quad (\mbox{if}~u \notin \free{\sembrack{\Gamma}})
%%%\end{eqnarray*}
%%%\caption{Constraint generation algorithm.}
%%%\label{fig:cgen}
%%%\end{figure*}

\subsubsection{Constraint Solving}
\label{sec:cs}

Given a set \(C\) of non-recursive Horn clauses, our previous constraint 
solving algorithm returns a substitution \(\theta\) for predicate 
variables in \(C\) such that \(\theta C\) is valid.
%in a backward manner
The algorithm iteratively finds a solution for each predicate variable 
\(P\) in \(C\) by using its greatest lower \(\lambda \seq{x}.\phi_{P}\) 
and least upper \(\lambda \seq{x}.\phi_{P}'\) bounds with respect to the 
partial order \(\sqsubseteq\) of predicates defined by: \(\lambda 
\seq{x}.\phi_1 \sqsubseteq \lambda \seq{x}.\phi_2\) if and only if 
\(\phi_1 \imply \phi_2\).  
%
Intuitively, the predicate \(P(\seq{x})\) represents an invariant of 
some subexpression \(e\) in the SHP such that some variable \(\nu \in 
\set{\seq{x}}\) represents the value of \(e\) and \(\FV{e} \subseteq 
\set{\seq{x}} \setminus \set{\nu}\).  The greatest lower \(\lambda 
\seq{x}.\phi_P\) and the least upper \(\lambda \seq{x}.\phi_{P}'\) 
bounds for \(P\) respectively represent the strongest condition 
satisfied by the value \(\nu\) and the weakest condition on \(\nu\) 
required by the context of \(e\).
%
The algorithm then computes \(\lambda \seq{x}.\mathcal{I}(\phi_P,\neg 
\phi_P')\) as a solution for \(P\) with the help of a technique called 
interpolation~\cite{Henzinger2004,McMillan2005} from automated theorem 
proving.  Here, an interpolant \(\mathcal{I}(\phi_1,\phi_2)\) of 
\(\phi_1\) and \(\phi_2\) (such that \(\phi_1\) and \(\phi_2\) are 
inconsistent) is a formula \(\phi\) that satisfies the following 
conditions:\footnote{Note here that interpolants of \(\phi_1\) and 
\(\phi_2\) are not unique.  Actually, existing theorem 
provers~\cite{Henzinger2004,McMillan2005,Beyer2008} return one of them. 
We denote such an interpolant as \(\mathcal{I}(\phi_1,\phi_2)\).}
\begin{itemize}
\item \(\phi_1\) implies \(\phi\),
\item \(\phi\) and \(\phi_2\) are inconsistent, and
\item \(\FV{\phi} \subseteq \FV{\phi_1} \cap \FV{\phi_2}\).
\end{itemize}
%
For example, for \(C_{\texttt{copy}}\), we obtain the following greatest 
lower and least upper bounds for \(P_1\) from \(C_{\texttt{copy}}\):
\begin{itemize}
\item \(\lambda x.\lambda \nu.\phi_{P_1}\equiv \lambda x.\lambda \nu.x=1 \land \nu=1\) and
\item \(\lambda x.\lambda \nu.\phi_{P_1}'\equiv \lambda x.\lambda \nu.\nu=x\).
\end{itemize}
We then obtain, for example, the following solution for \(P_1\):
\begin{eqnarray*}
\lambda x.\lambda \nu.\mathcal{I}(\nu.x=1 \land \nu=1,\neg \nu=x) \equiv \lambda x.\lambda \nu.\nu=x.
\end{eqnarray*}
By substituting this for \(P_1\) in \(C_{\texttt{copy}}\), we get 
\(C_{\texttt{copy}}'\):
\begin{eqnarray*}
P_2(x-1,y) \land x\neq0 \land z=1+y &\imply& z=x \\
x=0 \land y=0 &\imply& P_2(x,y)
\end{eqnarray*}
We then get the following greatest lower and least upper bounds for 
\(P_2\) from \(C_{\texttt{copy}}'\):
\begin{itemize}
\item \(\lambda x.\lambda \nu. \phi_{P_2}' \equiv \lambda x.\lambda \nu. x+1\neq0 \imply \nu=x\) and
\item \(\lambda x.\lambda \nu. \phi_{P_2} \equiv \lambda x.\lambda \nu. x=0 \land \nu=0\).
\end{itemize}
We then obtain, for example, the following solution for \(P_2\):
\begin{eqnarray*}
\lambda x.\lambda \nu.\mathcal{I}(\nu.x=0 \land \nu=0,\neg (x+1\neq0 \imply \nu=x)) \equiv \lambda x.\lambda \nu.\nu=x.
\end{eqnarray*}
We thus obtain the following refinement types for \(D_{\texttt{copy}}\):
\begin{eqnarray*}
\texttt{copy1}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid x=\nu}}) \\
\texttt{copy2}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid x=\nu}})
\end{eqnarray*}

\subsection{Limitation of Previous Method}
\label{sec:limit}

We now explain a limitation of the previous method by using the program 
in Figure~\ref{fig:copy}.  For example, let us consider the following 
SHP \(D_{\texttt{cc}}\):
\begin{alltt}
let copy1 x = assume (x<>0); 1 + copy2 (x-1)
let copy2 x = assume (x=0); 0
let copy3 x = assume (x<>0); 1 + copy4 (x-1)
let copy4 x = assume (x=0); 0
let main n = assume (copy3 (copy1 n) <> n); fail
\end{alltt}
The SHP corresponds to an infeasible error path where the else-branch of 
\(\texttt{copy}\) is taken in the first and the third calls of 
\(\texttt{copy}\), the then-branch is taken in the second and the fourth 
calls of \(\texttt{copy}\), and the assertion in the \(\texttt{main}\) 
function fails.

For the SHP \(D_{\texttt{cc}}\), we use the following type templates:
\begin{eqnarray*}
\texttt{copy1}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid P_1(x,\nu)}}) \\
%\texttt{copy2}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid P_2(x,\nu)}}) \\
%\texttt{copy3}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid P_3(x,\nu)}}) \\
\vdots\quad &&\qquad\qquad \vdots \\
\texttt{copy4}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid P_4(x,\nu)}})
\end{eqnarray*}
And, we get the following set \(C_{\texttt{cc}}\) of constraints:
\begin{eqnarray*}
P_2(x-1,y) \land x\neq0 \land z=1+y &\imply& P_1(x,z) \\
x=0 \land y=0 &\imply& P_2(x,y) \\
P_4(x-1,y) \land x\neq0 \land z=1+y &\imply& P_3(x,z) \\
x=0 \land y=0 &\imply& P_4(x,y) \\
P_1(n,x) \land P_3(x,y) &\imply& y=n
\end{eqnarray*}

We then find a solution for \(P_3\) as follows.  The greatest lower and 
the least upper bounds of \(P_3\) are respectively \(\lambda x.\lambda 
\nu.x=1 \land \nu=1\) and \(\lambda x.\lambda \nu.x=1 \imply \nu=1\).
%\(\lambda x,n=1 \land x=1 \imply \nu=n\).
%
Existing interpolating proves such as \cite{Beyer2008} then returns the 
following solution for \(P_3\):
\begin{eqnarray*}
%&&\lambda x.\lambda \nu.\mathcal{I}(\nu.x=1 \land \nu=1,\neg (n=1 \land x=1 \imply \nu=n)) \\
&&\lambda x.\lambda \nu.\mathcal{I}(\nu.x=1 \land \nu=1,\neg (x=1 \imply \nu=1)) \\
&\equiv& \lambda x.\lambda \nu.x=1 \land \nu=1.
\end{eqnarray*}
Note here that the solution is specific to the calling context of the 
particular function \texttt{copy3}, and cannot be used as a solution for 
\(P_2\) and \(P_4\).  We here want to get more general predicates like 
\(\lambda x.\lambda \nu.\nu=x\) which are more likely to constitute an invariant 
of the function \texttt{copy} in the original program.  For this purpose, 
we observe it is desirable to find the same solution (if possible) for 
``related'' predicate variables which represent (possibly different) 
refinement predicates for the same argument or return value of the same 
function in the original program.  For the above example, we want to 
obtain the same solution for \(P_1,\dots,P_4\), and \(\lambda 
x.\lambda \nu.\nu=x\) in fact satisfies this extra constraint.

\subsection{Extended Method}
\label{sec:ext}

We now explain our extension of the previous method to remedy the 
limitation discussed in Section~\ref{sec:limit}.  The extended predicate 
discovery method is based on the framework of the previous method 
overviewed in Section~\ref{sec:prev}, but the component for refinement 
type inference is extended so that it can merge and generalize 
information from multiple calling contexts of a function in multiple 
infeasible error paths.  This enables MoCHi to infer a general 
refinement type of the function that type-checks the multiple calling 
contexts, while preserving the path- and context-sensitivity.  In other 
words, the extended method generates constraints from multiple 
infeasible error paths (see Section~\ref{sec:extcg}), and tries to find 
the same solution (if possible) for related predicate variables (see 
Section~\ref{sec:extcs}).

\subsubsection{Extensions of Constraint Generation}
\label{sec:extcg}

We extend the previous constraint generation algorithm overviewed in 
Section~\ref{sec:cg} as follows.
\begin{itemize}
\item For each CEGAR iteration, we generate constraints from multiple 
infeasible error paths instead of a single path:  We keep the set 
\(\set{\pi_1,\cdots,\pi_n}\) of the infeasible error paths found so far, 
generate the set \(C_i\) of Horn clauses for each path \(\pi_i\), and 
pass \(C=C_1 \cup \dots \cup C_n\) to the extended constraint solving 
algorithm described in Section~\ref{sec:extcs} as an input.
%For example, \todo{}
\item We also generate and pass an equivalence relation \(E\) on the 
predicate variables in \(C_1 \cup \dots \cup C_n\) such that \(P\ E\ Q\) 
if and only if the predicate variables \(P\) and \(Q\) represent 
(possibly different) refinement predicates for the same argument or 
return value of the same function in the original program.  For example, 
for the constraints \(C_{\texttt{cc}}\), we obtain the trivial 
equivalence relation \(E_{\texttt{cc}}=\set{P_1,\dots,P_4} \times 
\set{P_1,\dots,P_4}\).  The constraint solving algorithm in 
Section~\ref{sec:extcs} exploits \(E\) to find general solutions for the 
constraints.
\end{itemize}
Thus, the extended algorithm generates a pair \((C,E)\) of Horn clauses 
\(C\) for multiple paths and an equivalence relation \(E\) on the 
predicate variables in \(C\) unlike the previous algorithm which 
generates only Horn clauses for a single path.  The pair \((C,E)\) is 
viewed as hierarchical constraints where \(C\) must be always satisfied 
and \(E\) should be satisfied if possible.

\subsubsection{Extensions of Constraint Solving}
\label{sec:extcs}

In this section, we propose an extension of the previous constraint 
solving algorithm overviewed in Section~\ref{sec:cs}.  Given a set \(C\) 
of Horn clauses and an equivalence relation \(E\) on the predicate 
variables in \(C\), the algorithm returns a substitution \(\theta\) for 
predicate variables in \(C\) such that \(\theta C\) is valid.  A 
distinguishing feature of the algorithm is that it tries to find the 
same solution for predicate variables related by \(E\) if possible.  
This feature enables the algorithm to find general predicates, which are 
more likely to constitute invariants of the original program.

%%%\begin{figure}
%%%\todo{}
%%%\caption{The Overall Structure of Our Extended Constraint Solving Algorithm}
%%%\label{fig:extcs}
%%%\end{figure}

We now explain how the algorithm works.
%%%The overall structure of the algorithm is shown in Figure~\ref{fig:extcs}.
The algorithm finds a set of predicate variables \(S\) that may have the 
same solution, a candidate solution \(\lambda \set{x}.\phi_0\) for \(S\), 
and a maximal subset \(S\) of \(M\) such that \(\phi_0\) is in fact a 
genuine solution for \(M\).  The algorithm then substitute \(\lambda 
\set{x}.\phi_0\) for \(M\)
\todo{}

%
First, we compute the greatest lower \(\lambda \seq{x}.\phi_P\) and the 
least upper \(\lambda \seq{x}.\phi_P'\) bounds for each predicate 
variable \(P\) in \(C\).  Here, \(\FV{\phi_P} \cap \FV{\phi_P'} 
\subseteq \set{\seq{x}}\) holds.  For example, the greatest lower bounds 
for \(P_1,\dots,P_4\) in \(C_{\texttt{cc}}\) are respectively:
\begin{itemize}
\item \(\lambda x.\lambda \nu.\phi_{P_1}\equiv \lambda x.\lambda \nu.x=1 \land \nu=1\),
\item \(\lambda x.\lambda \nu.\phi_{P_2}\equiv \lambda x.\lambda \nu.x=0 \land \nu=0\),
\item \(\lambda x.\lambda \nu.\phi_{P_3}\equiv \lambda x.\lambda \nu.x=1 \land \nu=1\), and
\item \(\lambda x.\lambda \nu.\phi_{P_4}\equiv \lambda x.\lambda \nu.x=0 \land \nu=0\).
\end{itemize}
The least upper bounds for \(P_1,\dots,P_4\) are respectively:
\begin{itemize}
\item \(\lambda x.\lambda \nu.\phi_{P_1}'\equiv \lambda x.\lambda \nu.\nu=1 \imply x=1\),
\item \(\lambda x.\lambda \nu.\phi_{P_2}'\equiv \lambda x.\lambda \nu.\nu=0 \imply (x=-1 \lor x=0)\),
\item \(\lambda x.\lambda \nu.\phi_{P_3}'\equiv \lambda x.\lambda \nu.x=1 \imply \nu=1\), and
\item \(\lambda x.\lambda \nu.\phi_{P_4}'\equiv \lambda x.\lambda \nu.x=0 \imply \nu=0\).
\end{itemize}

In general, the computation of the least upper bound for some predicate 
variable may possibly fail because the constraint generation algorithm 
in Section~\ref{sec:extcg} may generate a Horn clause of the form 
\(P(x)\land P(y) \imply \phi\).  Note here that \(P\) occurs twice in 
the left hand side of the constraint.  In such a case, the least upper 
bound for \(P\) may not exist.

Let \(S\) be the set of predicate variables in \(C\) whose least upper 
bounds were successfully computed.  We then pick an equivalence class 
\(S_0 \in S / E\) (e.g., the largest one), and further classify the 
predicate variables in \(S_0\) depending on their upper and lower bounds 
so that predicate variables which never have the same solution are 
separated.
%
Formally, we find \(S_1\dots,S_n\) such that:
\begin{itemize}
\item \(S_0 = S_1 \cup \dots \cup S_n\),
\item for any \(i \in \set{1,\dots,n}\), if \(S_i 
=\set{Q_1,\dots,Q_{\ell}}\), then \(\phi_{Q_1} \lor \dots \lor 
\phi_{Q_{\ell}}\) implies \(\phi_{Q_1}' \land \dots \land 
\phi_{Q_{\ell}}'\), and \item for any \(i,j \in \set{1,\dots,n}\), if 
\(i \neq j\) and \(S_i \cup S_j = \set{Q_1,\dots,Q_{\ell}}\), then 
\(\phi_{Q_1} \lor \dots \lor \phi_{Q_{\ell}}\) does not imply 
\(\phi_{Q_1}' \land \dots \land \phi_{Q_{\ell}}'\).
\end{itemize}
For the running example \(C_{\texttt{cc}}\), we get 
\(S=S_0=S_1=\set{P_1,\dots,P_4}\) since \(\phi_{P_1} \lor \dots 
\lor\phi_{P_4}\) implies \(\phi_{P_1}' \land \dots \land \phi_{P_4}'\).

We then pick some \(S_i = \set{Q_1,\dots,Q_{\ell}} \in 
\set{S_1,\dots,S_n}\) (e.g., the largest one) and find a predicate 
\(\lambda\seq{x}.\phi\) as a candidate solution for 
\(Q_1,\dots,Q_{\ell}\) such that:
\begin{itemize}
\item \(\phi_{Q_1} \lor \dots \lor \phi_{Q_{\ell}}\) implies \(\phi\),
\item \(\phi\) implies \(\phi_{Q_1}' \land \dots \land \phi_{Q_{\ell}}'\), and
\item \(\FV{\phi} \subseteq \set{\seq{x}}\).
\end{itemize}
%Terauchi2010
We can compute such a formula \(\phi\) as an interpolant 
\(\mathcal{I}(\phi_{Q_1} \lor \dots \lor \phi_{Q_{\ell}},\neg 
(\phi_{Q_1}' \land \dots \land \phi_{Q_{\ell}}'))\).

The three conditions of interpolants, however, are not always sufficient 
for our purpose to find general predicates.  Actually, we want to obtain 
as simple interpolant as possible with respect to the number of 
disjunctions.
% and conjunctions.
To this end, we propose a new heuristic operator \(\mathcal{J}\) that
combines the interpolation \(\mathcal{I}\) and the convex hull operators.
 Let us write \(\mathcal{H}(\phi)\) to denote the convex hull of \(\phi\).
 For formulas \(\phi_1\) and \(\phi_2\) (such that \(\phi_1\) and
\(\phi_2\) are inconsistent), the new operator
\(\mathcal{J}(\phi_1,\phi_2)\) is defined as follows:
\begin{eqnarray*}
\mathcal{J}(\phi_1,\phi_2) =
\left\{
\begin{array}{ll}
\mathcal{I}(\mathcal{H}(\phi_1),\mathcal{H}(\phi_2)) & (\mbox{if~}\mathcal{H}(\phi_1) \INCON \mathcal{H}(\phi_2)) \\
\mathcal{I}(\mathcal{H}(\phi_1),\phi_2) & (\mbox{if~}\neg (\mathcal{H}(\phi_1) \INCON \mathcal{H}(\phi_2)) \land \\
&\ \quad \mathcal{H}(\phi_1) \INCON \phi_2) \\
\mathcal{I}(\phi_1,\phi_2) & (\mbox{otherwise})
\end{array}
\right.
\end{eqnarray*}
Here, we write \(\phi_1 \INCON \phi_2\) to denote that \(\phi_1\) and
\(\phi_2\) are inconsistent.  Note that the use of the convex hull
operator enables us to eliminate disjunctions in \(\phi_1\) and
\(\phi_2\), which are passed to an interpolating theorem prover.
%the interpolation operator \(\mathcal{I}\).
In the experiments reported in Section~\ref{sec:experiments}, this often
reduced the number of disjunctions in the output of the interpolating
prover, and hence makes the output more likely to constitute invariants.
%
Thus, instead of using the interpolation operator \(\mathcal{I}\), we 
use the new operator \(\mathcal{J}\) to compute \(\lambda \seq{x}. 
\phi_0=\lambda\seq{x}.\mathcal{J}(\phi_{Q_1} \lor \dots\lor 
\phi_{Q_{\ell}},\neg (\phi_{Q_1}' \land \dots \land\phi_{Q_{\ell}}'))\) 
as a candidate solution for \(Q_1,\dots,Q_{\ell}\).  For the running 
example \(C_{\texttt{cc}}\), we obtain:
\begin{eqnarray*}
\phi_0 &=& \mathcal{J}(\phi_{P_1} \lor \dots \lor \phi_{P_4},\neg (\phi_{P_1}' \land \dots \land \phi_{P_4}')) \\
&=& \mathcal{I}(\mathcal{H}(\phi_{P_1} \lor \dots \lor \phi_{P_4}),\neg (\phi_{P_1}' \land \dots \land \phi_{P_4}')) \\
&=& \mathcal{I}(\mathcal{H}(x=0 \land \nu=0 \lor x=1 \land \nu=1),\neg (\phi_{P_1}' \land \dots \land \phi_{P_4}')) \\
&=& \mathcal{I}(0 \leq x=\nu \leq 1,\neg (\phi_{P_1}' \land \dots \land \phi_{P_4}'))
\end{eqnarray*}
An interpolating prover returned \(\lambda x \lambda \nu.\phi_0 \equiv
\lambda x \lambda \nu.x=\nu\) as a candidate solution for
\(P_1,\dots,P_4\) in the experiments in Section~\ref{sec:experiments}.

Note, however, that \(\lambda \seq{x}.\phi_0\) is not always a genuine 
solution for all the predicates \(Q_1,\dots,Q_{\ell} \in S_i\) because 
\(Q_i\) may depend on \(Q_j\) for some \(i \neq j\).  For example, let 
us consider the following constraints:
\begin{eqnarray*}
x=0 &\imply& Q_1(x) \\
Q_1(x) &\imply& Q_2(x+1) \\
Q_2(x) &\imply& 0 \leq x \leq 2
\end{eqnarray*}
The greatest lower bounds of \(Q_1\) and \(Q_2\) are respectively 
\(\lambda \nu.\nu=0\) and \(\lambda \nu.\nu=1\).  The least upper bounds 
of \(Q_1\) and \(Q_2\) are respectively \(\lambda \nu.-1 \leq \nu\leq 1\) 
and \(\lambda \nu.0 \leq \nu \leq 2\).  We then obtain, for example, 
\(\lambda \nu.\mathcal{J}(\nu=0 \lor \nu=1,\neg (-1 \leq \nu\leq 1 \land 
0 \leq \nu \leq 2)) \equiv \lambda \nu.0 \leq \nu \leq 1\) as a 
candidate solution for \(Q_1\) and \(Q_2\).  However, \([\lambda\nu.0 
\leq \nu \leq 1/Q_1,\lambda \nu.0 \leq \nu \leq 1/Q_2](Q_1(x) \imply 
Q_2(x+1))\) is not valid.  In this example, we are actually only allowed 
to substitute the candidate solution \(\lambda \nu.0 \leq \nu\leq 1\) 
for either \(Q_1\) or \(Q_2\).

Therefore, we find a maximal subset \(M=\set{R_1,\dots,R_m} \neq 
\emptyset\) of \(S_i\) such that 
\([\lambda\seq{x}.\phi_0/R_1,\dots,\lambda\seq{x}.\phi_0/R_m]C\) is 
equisatisfiable with \(C\).  As a result, the candidate solution 
\(\lambda\seq{x}.\phi_0\) is in fact a genuine solution for 
\(R_1,\dots,R_m\).
%
%%%such that \(\lambda\seq{x}.\phi_0\) is in fact a solution for every predicate variable in \(M\).
%
%%%Formally, we find \(M=\set{R_1,\dots,R_m}\) such that:
%%%\begin{itemize}
%%%\item \(M \subseteq S_i\),
%%%\item \(\theta[\lambda \seq{x}.\phi_0/R_1,\dots,\lambda 
%%%\seq{x}.\phi_0/R_m]C\) is valid for some substitution \(\theta\) for 
%%%predicate variables, and
%%%\item for any \(R_0 \in S_i \setminus M\) and \(\theta\) the following 
%%%formula is not valid: \(\theta[\lambda \seq{x}.\phi_0/R_0,\lambda 
%%%\seq{x}.\phi_0/R_1,\dots,\lambda \seq{x}.\phi_0/R_m]C\).
%%%\end{itemize}
For the running example \(C_{\texttt{cc}}\), \(\lambda x \lambda 
\nu.\phi_0 \equiv \lambda x \lambda \nu.x=\nu\) is in fact a genuine 
solution for \(P_1,\dots,P_4\) (i.e., \(M=S_1\)).

We then substitute the solution \(\lambda \seq{x}.\phi_0\) for 
\(R_1,\dots,R_m \in M\), and repeat the entire constraint solving 
procedure until every predicate variable in \(C\) is substituted.  For 
the running example \(C_{\texttt{cc}}\), we finally obtain the following 
refinement types of \(D_{\texttt{cc}}\):
\begin{eqnarray*}
\texttt{copy1}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid x=\nu}}) \\
%\texttt{copy2}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid x=\nu}}) \\
%\texttt{copy3}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid x=\nu}}) \\
\vdots\quad &&\qquad\qquad \vdots \\
\texttt{copy4}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid x=\nu}})
\end{eqnarray*}

%\todo{discuss termination?}

%%%infer a refinement type of each
%%%subexpression \(e\) of an ordinary ML type \(\tau\):
%%%  The method then computes an
%%%interpolant \(\phi\) of \(\phi_{post}\) and \(\phi_{pre}\), and returns
%%%\(\set{\nu:\tau \mid \phi}\) as a refinement type of \(e\).
%
%%%%Thus, the method considers both forward and backward information of \(e\)
%%%%respectively obtained from \(e\) and the context of \(e\).
