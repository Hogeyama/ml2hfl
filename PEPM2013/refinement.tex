\input{macro}

\section{Predicate Discovery}
\label{sec:refine}

In this section, we propose a new predicate discovery method for
higher-order programs.  The method is based on our previous one used by
MoCHi~\cite{KobayashiPLDI2011}, which we briefly overview below.

In MoCHi, predicates for abstracting each term of a given program are
specified as a kind of dependent types called abstraction types.  MoCHi
infers abstraction types automatically in a counterexample-guided manner:
 In a CEGAR iteration of MoCHi, if the predicate abstraction at that
point is not precise enough to show the safety of the original program,
an error path of the abstracted program is returned as a result of
higher-order model checking (see Fig.~\ref{fig:cegar}).  If the abstract
error path is infeasible (i.e., not a genuine path of the original
program), MoCHi generates a straightline higher-order program (SHP)
which is safe if and only if the abstract error path is infeasible .
MoCHi then uses an existing method~\cite{Unno2009} to infer refinement
types that witness the safety of the SHP.  Finally, MoCHi extracts
abstraction types from the refinement types, which contain precise
enough predicates to refute the infeasible error path.

Our new predicate discovery method is based on the above framework but
the component for refinement type inference is extended so that it can
merge and generalize information from multiple calling contexts of a
function in multiple infeasible error paths.  This enables MoCHi to
infer a general refinement type of the function that type-checks the
multiple calling contexts, while preserving the path- and context-
sensitivity.  Our new refinement type inference method consists of two
steps: constraint generation and solving, which are respectively
explained in Sections~\ref{sec:cg} and \ref{sec:cs}.

\subsection{Constraint Generation}
\label{sec:cg}

In this section, we extend the constraint generation algorithm used in
previous work~\cite{Unno2009,Terauchi2010,KobayashiPLDI2011}.  Before we
discuss the extension, we briefly overview the previous algorithm.  Let
us assume that we are given a SHP \(D\) which is typable under a
refinement type system (see e.g., \cite{Unno2009} for the definition) if
and only if the abstract error path is infeasible.  For example, for the
program in Figure~\ref{fig:copy}, we may obtain the following SHP
\(D_{\texttt{copy}}\):
\begin{alltt}
let copy1 x = assume (x<>0); 1 + copy2 (x-1)
let copy2 x = assume (x=0); 0
let copy3 x = assume (x<>0); 1 + copy4 (x-1)
let copy4 x = assume (x=0); 0
let main n = assume (copy3 (copy1 n) <> n); fail
\end{alltt}
The SHP corresponds to an infeasible error path where the else-branch of
\(\texttt{copy}\) is taken in the first and the third function call of
\(\texttt{copy}\), the then-branch is taken in the second and the fourth
function calls of \(\texttt{copy}\), and the assertion in the
\(\texttt{main}\) function fails.

From a SHP \(D\), we generate Horn-clause-like constraints which are
satisfiable if and only if \(D\) is typable.  To this end, for each
function in \(D\), we prepare a refinement type template with predicate
variables, which act as placeholders of refinement predicates to be
inferred.  We then generate a typing derivation for \(D\) under the type
environment that associates each function with its type template.
Horn-clause-like constraints on the predicate variables are then
extracted from the derivation.  Since the SHP \(D\) is recursion-free
and linear (i.e., each function is called exactly once), generated
constraints are non-recursive.  This is desirable since constraint
solving of non-recursive Horn clauses over linear arithmetic is
decidable.  For example, for the SHP \(D_{\texttt{copy}}\), we use the
following type templates:\footnote{For the sake of simplicity of the
presentation, we here omit the type template of \texttt{main} as well as
the refinement predicates for the argument of
\texttt{copy1}--\texttt{copy4}.}
\begin{eqnarray*}
\texttt{copy1}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid P_1(x,\nu)}}) \\
%\texttt{copy2}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid P_2(x,\nu)}}) \\
%\texttt{copy3}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid P_3(x,\nu)}}) \\
\vdots\quad &&\qquad\qquad \vdots \\
\texttt{copy4}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid P_4(x,\nu)}})
\end{eqnarray*}
By using them, we obtain the following set \(C_{\texttt{copy}}\) of
constraints:
\begin{eqnarray*}
P_2(x-1,y) \land x\neq0 \land z=1+y &\imply& P_1(x,z) \\
x=0 \land y=0 &\imply& P_2(x,y) \\
P_4(x-1,y) \land x\neq0 \land z=1+y &\imply& P_3(x,z) \\
x=0 \land y=0 &\imply& P_4(x,y) \\
P_1(n,x) \land P_3(x,y) &\imply& y=n
\end{eqnarray*}

We extend the previous algorithm overviewed above as follows.
\begin{itemize}
\item For each CEGAR iteration, we infer refinement types from multiple
infeasible error paths instead of a single path:  We keep the set
\(\set{\pi_1,\cdots,\pi_n}\) of the infeasible error paths found so far,
generate the set \(C_i\) of Horn clauses for each path \(\pi_i\), and
pass \(C_1 \cup \dots \cup C_n\) to the constraint solving algorithm
described in Section~\ref{sec:cs} as an input.  %For example, \todo{}
\item We also pass an equivalence relation \(E\) on the predicate
variables in \(C_1 \cup \dots \cup C_n\) such that \(P\ E\ Q\) if and
only if the predicate variables \(P\) and \(Q\) represent (possibly
different) refinement predicates for the same argument of the same
function in the original program.  For example, for the constraints
\(C_{\texttt{copy}}\), we obtain the trivial equivalence relation
\(E_{\texttt{copy}}=\set{P_1,\dots,P_4} \times \set{P_1,\dots,P_4}\).
The constraint solving algorithm in Section~\ref{sec:cs} exploits \(E\)
to find general solutions for the constraints.
\end{itemize}

%%%We then use the constraint generation algorithm for terms defined in
%%%Figure~\ref{fig:cgen} to obtain constraints.  In the figure,
%%%$\CG{\Gamma}{e}$ returns a pair of a refinement type $\tau$ and a
%%%constraint $\theta$ such that $\Gamma \vdash e : \tau$ is derivable if
%%%and only if $\theta$ is valid. Similarly, $\CS{\Gamma}{\tau_1}{\tau_2}$
%%%returns a constraint $\theta$ such that $\Gamma \vdash \tau_1 \leq
%%%\tau_2$ is derivable if and only if $\theta$ is valid.
%%%%
%%%The algorithm is almost a straightforward modification of the typing and
%%%subtyping rules in Section~\ref{sec:reftypesystem} except that the
%%%application of the subsumption rule is restricted to the acutal argument
%%%of function applications.


%%%\begin{figure*}[tbh]
%%%\begin{eqnarray*}
%%%\CG{\Gamma}{x}
%%%&=&(\reftype{u}{u = x},\top) \quad (\mbox{if}~\sty{x}=\inttype) \\
%%%\CG{\Gamma}{\kappa}
%%%&=&(\Gamma(\kappa),\top) \quad (\mbox{if}~\sty{\kappa} \in \rightarrow) \\
%%%\CG{\Gamma}{c}
%%%&=&(\cty{c},\top) \\
%%%\CG{\Gamma}{\ttlet{x}{e_1}{e_2}}
%%%&=&\mbox{let~}(\sigma,\theta_1)=\CG{\Gamma}{e_1} \\
%%%& &\mbox{let~}(\cpstype,\theta_2)=\CG{\Gamma,x\smallcolon\sigma}{e_2} \\
%%%& &(\cpstype,\theta_1 \land \theta_2) \\
%%%\CG{\Gamma}{\ttapp{e}{x}}
%%%&=&\mbox{let~}(\funtype{y}{\sigma}{\tau},\theta_1)=\CG{\Gamma}{e} \\
%%%& &\mbox{let~}(\sigma',\theta_2)=\CG{\Gamma}{x} \\
%%%& &(\tau[x/y],\theta_1 \land \theta_2 \land \CS{\Gamma}{\sigma'}{\sigma}) \\
%%%\CG{\Gamma}{\ttifndet{e_1}{e_2}}
%%%&=&\mbox{let~}(\cpstype,\theta_1)=\CG{\Gamma}{e_1} \\
%%%& &\mbox{let~}(\cpstype,\theta_2)=\CG{\Gamma}{e_2} \\
%%%& &(\cpstype,\theta_1 \land \theta_2) \\
%%%\CS{\Gamma}{\cpstype}{\cpstype}
%%%&=&\top \\
%%%\CS{\Gamma}{\funtype{x}{\sigma_1}{\tau_1}}{\funtype{x}{\sigma_2}{\tau_2}}
%%%&=&\CS{\Gamma}{\sigma_2}{\sigma_1} \land \CS{\Gamma,x:\sigma_2}{\tau_1}{\tau_2} \\
%%%\CS{\Gamma}{\reftype{u}{\theta_1}}{\reftype{u}{\theta_2}}
%%%&=&\forall u.(\sembrack{\Gamma} \wedge \theta_1) \imply \theta_2  \quad (\mbox{if}~u \notin \free{\sembrack{\Gamma}})
%%%\end{eqnarray*}
%%%\caption{Constraint generation algorithm.}
%%%\label{fig:cgen}
%%%\end{figure*}



\subsection{Constraint Solving}
\label{sec:cs}

In this section, we propose a new algorithm for solving Horn-clause-like
constraints.  Given a set \(C\) of Horn clauses and an equivalence
relation \(E\) on the predicate variables in \(C\), the algorithm
returns a substitution \(\theta\) for predicate variables in \(C\) such
that \(\theta C\) is valid.  A distinguishing feature of the algorithm
is that it finds the same solution for predicate variables related by
\(E\) when possible.  This feature enables the algorithm to find general
predicates, which are more likely to constitute invariants of the
original program.

We now explain how the algorithm works.  First, we compute the strongest
lower \(\lambda \seq{x}\lambda \nu.\phi_P\) and the weakest upper
\(\lambda \seq{x}\lambda \nu.\phi_P'\) bounds for each predicate
variable \(P\) in \(C\).  Here, \(\FV{\phi_P} \subseteq
\set{\seq{x},\nu}\) and \(\FV{\phi_P'} \subseteq \set{\seq{x},\nu}\).
Intuitively, \(P\) represents an invariant of some subexpression \(e\)
in the SHPs such that \(\FV{e} \subseteq \set{\seq{x}}\), and \(\nu\)
represents the value of \(e\).  The strongest lower \(\phi_P\) and the
weakest upper \(\phi_{P}'\) bounds for \(P\) respectively represent the
strongest condition satisfied by the value \(\nu\) and the weakest
condition on \(\nu\) required by the context of \(e\).  For example, the
strongest lower bounds for \(P_1,\dots,P_4\) in \(C_{\texttt{copy}}\)
are respectively:
\begin{itemize}
\item \(\phi_{P_1}\equiv x=1 \land \nu=1\),
\item \(\phi_{P_2}\equiv x=0 \land \nu=0\),
\item \(\phi_{P_3}\equiv x=1 \land \nu=1\), and
\item \(\phi_{P_4}\equiv x=0 \land \nu=0\).
\end{itemize}
The weakest upper bounds for \(P_1,\dots,P_4\) are respectively:
\begin{itemize}
\item \(\phi_{P_1}'\equiv \nu=1 \imply x=1\),
\item \(\phi_{P_2}'\equiv \nu=0 \imply (x=-1 \lor x=0)\),
\item \(\phi_{P_3}'\equiv x=1 \imply \nu=1\), and
\item \(\phi_{P_4}'\equiv x=0 \imply \nu=0\).
\end{itemize}

In general, the computation of the upper bound for some predicate
variable may possibly fail because the constraint generation algorithm
in Section~\ref{sec:cg} may generate a Horn clause of the form \(P(x)
\land P(y) \imply \phi\).  Note here that \(P\) occurs twice in the left
hand side of the constraint.  In such a case, the weakest upper bound
for \(P\) may not exist.

Let \(S\) be the set of predicate variables in \(C\) whose upper bounds
were successfully computed.  We then pick an equivalence class \(S_0 \in
S / E\) (e.g., the largest one), and further classify the predicate
variables in \(S_0\) depending on their upper and lower bounds so that
predicate variables which never have the same solution are separated.
%
Formally, we find \(S_1\dots,S_n\) such that:
\begin{itemize}
\item \(S_0 = S_1 \cup \dots \cup S_n\),
\item for any \(i \in \set{1,\dots,n}\), if \(S_i =
\set{Q_1,\dots,Q_{\ell}}\), then \(\phi_{Q_1} \lor \dots \lor
\phi_{Q_{\ell}}\) implies \(\phi_{Q_1}' \land \dots \land
\phi_{Q_{\ell}}'\), and
\item for any \(i,j \in \set{1,\dots,n}\), if \(i \neq j\) and
\(S_i \cup S_j = \set{Q_1,\dots,Q_{\ell}}\), then \(\phi_{Q_1} \lor
\dots \lor \phi_{Q_{\ell}}\) does not imply \(\phi_{Q_1}' \land \dots
\land \phi_{Q_{\ell}}'\).
\end{itemize}
For the running example \(C_{\texttt{copy}}\), we get
\(S=S_0=S_1=\set{P_1,\dots,P_4}\) since \(\phi_{P_1} \lor \dots \lor
\phi_{P_4}\) implies \(\phi_{P_1}' \land \dots \land \phi_{P_4}'\).

We then pick some \(S_i = \set{Q_1,\dots,Q_{\ell}} \in
\set{S_1,\dots,S_n}\) (e.g., the largest one) and find a predicate
\(\lambda\seq{x}.\lambda \nu.\phi\) as a candidate solution for
\(Q_1,\dots,Q_{\ell}\) such that:
\begin{itemize}
\item \(\phi_{Q_1} \lor \dots \lor \phi_{Q_{\ell}}\) implies \(\phi\),
\item \(\phi\) implies \(\phi_{Q_1}' \land \dots \land \phi_{Q_{\ell}}'\), and
\item \(\FV{\phi} \subseteq \set{\seq{x},\nu}\).
\end{itemize}
%Terauchi2010
We can compute such a formula \(\phi\) as an interpolant
\(\mathcal{I}(\phi_{Q_1} \lor \dots \lor \phi_{Q_{\ell}},\neg
(\phi_{Q_1}' \land \dots \land \phi_{Q_{\ell}}'))\) by using a technique
called interpolation~\cite{Henzinger2004,McMillan2005} from automated
theorem proving.  Here, an interpolant \(\mathcal{I}(\phi_1,\phi_2)\) of
\(\phi_1\) and \(\phi_2\) (such that \(\phi_1\) and \(\phi_2\) are
inconsistent) is a formula \(\phi\) that satisfies the following
conditions:\footnote{Note here that interpolants of \(\phi_1\) and
\(\phi_2\) are not unique.  Actually, existing theorem
provers~\cite{Henzinger2004,McMillan2005,Beyer2008} return one of them.
We denote such an interpolant as \(\mathcal{I}(\phi_1,\phi_2)\).}
\begin{itemize}
\item \(\phi_1\) implies \(\phi\),
\item \(\phi\) and \(\phi_2\) are inconsistent, and
\item \(\FV{\phi} \subseteq \FV{\phi_1} \cap \FV{\phi_2}\).
\end{itemize}
The above conditions of interpolants, however, are not always sufficient
for our purpose to find general predicates which constitute invariants.
Actually, we want to obtain as simple interpolant as possible with
respect to the number of disjunctions.
% and conjunctions.
To this end, we propose a new heuristic operator \(\mathcal{J}\) that
combines the interpolation \(\mathcal{I}\) and the convex hull operators.
 Let us write \(\mathcal{H}(\phi)\) to denote the convex hull of \(\phi\).
 For formulas \(\phi_1\) and \(\phi_2\) (such that \(\phi_1\) and
\(\phi_2\) are inconsistent), the new operator
\(\mathcal{J}(\phi_1,\phi_2)\) is defined as follows:
\begin{eqnarray*}
\mathcal{J}(\phi_1,\phi_2) =
\left\{
\begin{array}{ll}
\mathcal{I}(\mathcal{H}(\phi_1),\mathcal{H}(\phi_2)) & (\mbox{if~}\mathcal{H}(\phi_1) \INCON \mathcal{H}(\phi_2)) \\
\mathcal{I}(\mathcal{H}(\phi_1),\phi_2) & (\mbox{if~}\neg (\mathcal{H}(\phi_1) \INCON \mathcal{H}(\phi_2)) \land \\
&\ \quad \mathcal{H}(\phi_1) \INCON \phi_2) \\
\mathcal{I}(\phi_1,\phi_2) & (\mbox{otherwise})
\end{array}
\right.
\end{eqnarray*}
Here, we write \(\phi_1 \INCON \phi_2\) to denote that \(\phi_1\) and
\(\phi_2\) are inconsistent.  Note that the use of the convex hull
operator enables us to eliminate disjunctions in \(\phi_1\) and
\(\phi_2\), which are passed to an interpolating theorem prover.
%the interpolation operator \(\mathcal{I}\).
In the experiments reported in Section~\ref{sec:experiments}, this often
reduced the number of disjunctions in the output of the interpolating
prover, and hence makes the output more likely to constitute invariants.
%
Thus, instead of using the interpolation operator \(\mathcal{I}\), we
use the new operator \(\mathcal{J}\) to compute \(\lambda\seq{x}.\lambda
\nu.\phi_0=\lambda\seq{x}.\lambda \nu.\mathcal{J}(\phi_{Q_1} \lor \dots
\lor \phi_{Q_{\ell}},\neg (\phi_{Q_1}' \land \dots \land
\phi_{Q_{\ell}}'))\) as a candidate solution for \(Q_1,\dots,Q_{\ell}\).
 For the running example \(C_{\texttt{copy}}\), we obtain:
\begin{eqnarray*}
\phi_0 &=& \mathcal{J}(\phi_{P_1} \lor \dots \lor \phi_{P_4},\neg (\phi_{P_1}' \land \dots \land \phi_{P_4}')) \\
&=& \mathcal{I}(\mathcal{H}(\phi_{P_1} \lor \dots \lor \phi_{P_4}),\neg (\phi_{P_1}' \land \dots \land \phi_{P_4}')) \\
&=& \mathcal{I}(0 \leq x=\nu \leq 1,\neg (\phi_{P_1}' \land \dots \land \phi_{P_4}'))
\end{eqnarray*}
An interpolating prover returned \(\lambda x \lambda \nu.\phi_0 \equiv
\lambda x \lambda \nu.x=\nu\) as a candidate solution for
\(P_1,\dots,P_4\) in the experiments in Section~\ref{sec:experiments}.

Note, however, that \(\lambda \seq{x} \lambda \nu.\phi_0\) is not always
a genuine solution for all the predicates \(Q_1,\dots,Q_{\ell} \in S_i\)
because \(Q_i\) may depend on \(Q_j\) for some \(i \neq j\).  For
example, let us consider the following constraints:
\begin{eqnarray*}
x=0 &\imply& Q_1(x) \\
Q_1(x) &\imply& Q_2(x+1) \\
Q_2(x) &\imply& 0 \leq x \leq 2
\end{eqnarray*}
The strongest lower bounds of \(Q_1\) and \(Q_2\) are respectively
\(\lambda \nu.\nu=0\) and \(\lambda \nu.\nu=1\).  The weakest upper
bounds of \(Q_1\) and \(Q_2\) are respectively \(\lambda \nu.-1 \leq \nu
\leq 1\) and \(\lambda \nu.0 \leq \nu \leq 2\).  We then obtain, for
example, \(\lambda \nu.\mathcal{J}(\nu=0 \lor \nu=1,\neg (-1 \leq \nu
\leq 1 \land 0 \leq \nu \leq 2)) \equiv \lambda \nu.0 \leq \nu \leq 1\)
as a candidate solution for \(Q_1\) and \(Q_2\).  However, \([\lambda
\nu.0 \leq \nu \leq 1/Q_1,\lambda \nu.0 \leq \nu \leq 1/Q_2](Q_1(x)
\imply Q_2(x+1))\) is not valid.  In this example, we are actually only
allowed to substitute the candidate solution \(\lambda \nu.0 \leq \nu
\leq 1\) for either \(Q_1\) or \(Q_2\).

Therefore, we find a maximal subset \(M\) of \(S_i\) such that
\(\lambda\seq{x}.\lambda \nu.\phi_0\) is in fact a solution for every
predicate variable in \(M\).  Formally, we find \(M=\set{R_1,\dots,R_m}\)
such that:
\begin{itemize}
\item \(M \subseteq S_i\),
\item \(\theta[\lambda\seq{x}.\lambda
\nu.\phi_0/R_1,\dots,\lambda\seq{x}.\lambda \nu.\phi_0/R_m]C\) is valid
for some substitution \(\theta\) for predicate variables, and
\item for any \(R_0 \in S_i \setminus M\) and \(\theta\) the following
formula is not valid: \(\theta[\lambda\seq{x}.\lambda
\nu.\phi_0/R_0,\lambda\seq{x}.\lambda
\nu.\phi_0/R_1,\dots,\lambda\seq{x}.\lambda \nu.\phi_0/R_m]C\).
\end{itemize}
For the running example \(C_{\texttt{copy}}\), \(\lambda x \lambda
\nu.\phi_0 \equiv \lambda x \lambda \nu.x=\nu\) is actually a genuine
solution for \(P_1,\dots,P_4\) (i.e., \(M=S_1\)).

We then substitute the solution \(\lambda x \lambda \nu.\phi_0\) for
\(R_1,\dots,R_m \in M\), and repeat the entire constraint solving
procedure until every predicate variable in \(C\) is substituted.  For
the running example \(C_{\texttt{copy}}\), we finally obtain the
following refinement types of \(D_{\texttt{copy}}\):
\begin{eqnarray*}
\texttt{copy1}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid x=\nu}}) \\
%\texttt{copy2}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid x=\nu}}) \\
%\texttt{copy3}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid x=\nu}}) \\
\vdots\quad &&\qquad\qquad \vdots \\
\texttt{copy4}&\COL&(x\COL\TFun{\INT}{\set{\nu\COL\INT \mid x=\nu}})
\end{eqnarray*}

%\todo{discuss termination?}

%%%infer a refinement type of each
%%%subexpression \(e\) of an ordinary ML type \(\tau\):
%%%  The method then computes an
%%%interpolant \(\phi\) of \(\phi_{post}\) and \(\phi_{pre}\), and returns
%%%\(\set{\nu:\tau \mid \phi}\) as a refinement type of \(e\).
%
%%%%Thus, the method considers both forward and backward information of \(e\)
%%%%respectively obtained from \(e\) and the context of \(e\).
